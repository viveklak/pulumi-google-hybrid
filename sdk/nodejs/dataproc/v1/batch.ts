// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import { input as inputs, output as outputs, enums } from "../../types";
import * as utilities from "../../utilities";

/**
 * Creates a batch workload that executes asynchronously.
 * Auto-naming is currently not supported for this resource.
 */
export class Batch extends pulumi.CustomResource {
    /**
     * Get an existing Batch resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, opts?: pulumi.CustomResourceOptions): Batch {
        return new Batch(name, undefined as any, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'google-hybrid:dataproc/v1:Batch';

    /**
     * Returns true if the given object is an instance of Batch.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is Batch {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === Batch.__pulumiType;
    }

    /**
     * The time when the batch was created.
     */
    public /*out*/ readonly createTime!: pulumi.Output<string>;
    /**
     * The email address of the user who created the batch.
     */
    public /*out*/ readonly creator!: pulumi.Output<string>;
    /**
     * Optional. Environment configuration for the batch execution.
     */
    public readonly environmentConfig!: pulumi.Output<outputs.dataproc.v1.EnvironmentConfigResponse>;
    /**
     * Optional. The labels to associate with this batch. Label keys must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if present, must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be associated with a batch.
     */
    public readonly labels!: pulumi.Output<{[key: string]: string}>;
    /**
     * The resource name of the batch.
     */
    public /*out*/ readonly name!: pulumi.Output<string>;
    /**
     * The resource name of the operation associated with this batch.
     */
    public /*out*/ readonly operation!: pulumi.Output<string>;
    /**
     * Optional. PySpark batch config.
     */
    public readonly pysparkBatch!: pulumi.Output<outputs.dataproc.v1.PySparkBatchResponse>;
    /**
     * Optional. Runtime configuration for the batch execution.
     */
    public readonly runtimeConfig!: pulumi.Output<outputs.dataproc.v1.RuntimeConfigResponse>;
    /**
     * Runtime information about batch execution.
     */
    public /*out*/ readonly runtimeInfo!: pulumi.Output<outputs.dataproc.v1.RuntimeInfoResponse>;
    /**
     * Optional. Spark batch config.
     */
    public readonly sparkBatch!: pulumi.Output<outputs.dataproc.v1.SparkBatchResponse>;
    /**
     * Optional. SparkR batch config.
     */
    public readonly sparkRBatch!: pulumi.Output<outputs.dataproc.v1.SparkRBatchResponse>;
    /**
     * Optional. SparkSql batch config.
     */
    public readonly sparkSqlBatch!: pulumi.Output<outputs.dataproc.v1.SparkSqlBatchResponse>;
    /**
     * The state of the batch.
     */
    public /*out*/ readonly state!: pulumi.Output<string>;
    /**
     * Historical state information for the batch.
     */
    public /*out*/ readonly stateHistory!: pulumi.Output<outputs.dataproc.v1.StateHistoryResponse[]>;
    /**
     * Batch state details, such as a failure description if the state is FAILED.
     */
    public /*out*/ readonly stateMessage!: pulumi.Output<string>;
    /**
     * The time when the batch entered a current state.
     */
    public /*out*/ readonly stateTime!: pulumi.Output<string>;
    /**
     * A batch UUID (Unique Universal Identifier). The service generates this value when it creates the batch.
     */
    public /*out*/ readonly uuid!: pulumi.Output<string>;

    /**
     * Create a Batch resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args?: BatchArgs, opts?: pulumi.CustomResourceOptions) {
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (!opts.id) {
            resourceInputs["batchId"] = args ? args.batchId : undefined;
            resourceInputs["environmentConfig"] = args ? args.environmentConfig : undefined;
            resourceInputs["labels"] = args ? args.labels : undefined;
            resourceInputs["location"] = args ? args.location : undefined;
            resourceInputs["project"] = args ? args.project : undefined;
            resourceInputs["pysparkBatch"] = args ? args.pysparkBatch : undefined;
            resourceInputs["requestId"] = args ? args.requestId : undefined;
            resourceInputs["runtimeConfig"] = args ? args.runtimeConfig : undefined;
            resourceInputs["sparkBatch"] = args ? args.sparkBatch : undefined;
            resourceInputs["sparkRBatch"] = args ? args.sparkRBatch : undefined;
            resourceInputs["sparkSqlBatch"] = args ? args.sparkSqlBatch : undefined;
            resourceInputs["createTime"] = undefined /*out*/;
            resourceInputs["creator"] = undefined /*out*/;
            resourceInputs["name"] = undefined /*out*/;
            resourceInputs["operation"] = undefined /*out*/;
            resourceInputs["runtimeInfo"] = undefined /*out*/;
            resourceInputs["state"] = undefined /*out*/;
            resourceInputs["stateHistory"] = undefined /*out*/;
            resourceInputs["stateMessage"] = undefined /*out*/;
            resourceInputs["stateTime"] = undefined /*out*/;
            resourceInputs["uuid"] = undefined /*out*/;
        } else {
            resourceInputs["createTime"] = undefined /*out*/;
            resourceInputs["creator"] = undefined /*out*/;
            resourceInputs["environmentConfig"] = undefined /*out*/;
            resourceInputs["labels"] = undefined /*out*/;
            resourceInputs["name"] = undefined /*out*/;
            resourceInputs["operation"] = undefined /*out*/;
            resourceInputs["pysparkBatch"] = undefined /*out*/;
            resourceInputs["runtimeConfig"] = undefined /*out*/;
            resourceInputs["runtimeInfo"] = undefined /*out*/;
            resourceInputs["sparkBatch"] = undefined /*out*/;
            resourceInputs["sparkRBatch"] = undefined /*out*/;
            resourceInputs["sparkSqlBatch"] = undefined /*out*/;
            resourceInputs["state"] = undefined /*out*/;
            resourceInputs["stateHistory"] = undefined /*out*/;
            resourceInputs["stateMessage"] = undefined /*out*/;
            resourceInputs["stateTime"] = undefined /*out*/;
            resourceInputs["uuid"] = undefined /*out*/;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        super(Batch.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * The set of arguments for constructing a Batch resource.
 */
export interface BatchArgs {
    /**
     * Optional. The ID to use for the batch, which will become the final component of the batch's resource name.This value must be 4-63 characters. Valid characters are /[a-z][0-9]-/.
     */
    batchId?: pulumi.Input<string>;
    /**
     * Optional. Environment configuration for the batch execution.
     */
    environmentConfig?: pulumi.Input<inputs.dataproc.v1.EnvironmentConfigArgs>;
    /**
     * Optional. The labels to associate with this batch. Label keys must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if present, must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be associated with a batch.
     */
    labels?: pulumi.Input<{[key: string]: pulumi.Input<string>}>;
    location?: pulumi.Input<string>;
    project?: pulumi.Input<string>;
    /**
     * Optional. PySpark batch config.
     */
    pysparkBatch?: pulumi.Input<inputs.dataproc.v1.PySparkBatchArgs>;
    /**
     * Optional. A unique ID used to identify the request. If the service receives two CreateBatchRequest (https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1#google.cloud.dataproc.v1.CreateBatchRequest)s with the same request_id, the second request is ignored and the Operation that corresponds to the first Batch created and stored in the backend is returned.Recommendation: Set this value to a UUID (https://en.wikipedia.org/wiki/Universally_unique_identifier).The value must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens (-). The maximum length is 40 characters.
     */
    requestId?: pulumi.Input<string>;
    /**
     * Optional. Runtime configuration for the batch execution.
     */
    runtimeConfig?: pulumi.Input<inputs.dataproc.v1.RuntimeConfigArgs>;
    /**
     * Optional. Spark batch config.
     */
    sparkBatch?: pulumi.Input<inputs.dataproc.v1.SparkBatchArgs>;
    /**
     * Optional. SparkR batch config.
     */
    sparkRBatch?: pulumi.Input<inputs.dataproc.v1.SparkRBatchArgs>;
    /**
     * Optional. SparkSql batch config.
     */
    sparkSqlBatch?: pulumi.Input<inputs.dataproc.v1.SparkSqlBatchArgs>;
}
